# Parallel_DNN_HPC
This research investigates the optimization of Deep Neural Networks (DNNs) training through a comparative analysis of two parallelization methods—Allreduce and Voting—implemented via the Message Passing Interface (MPI) on CIFAR10 and CIFAR100 datasets. 
